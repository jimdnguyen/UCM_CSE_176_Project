{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "colab": {
      "name": "GroupF_Project2_Part1_Neural_Network.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qKzjYwwIfHF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f42c19bf-fe80-41de-a1ff-49f36ac8f779"
      },
      "source": [
        "#%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "from torchvision import datasets\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "random_seed = 0\n",
        "random.seed(random_seed)\n",
        "torch.manual_seed(random_seed)\n",
        "torch.backends.cudnn.enabled = False \n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.cuda.manual_seed(random_seed)\n",
        "torch.cuda.manual_seed_all(random_seed)  # if you are using multi-GPU.\n",
        "np.random.seed(random_seed)\n",
        "g = torch.Generator()\n",
        "g.manual_seed(random_seed)\n",
        "#https://github.com/pytorch/pytorch/issues/7068\n",
        "#https://discuss.pytorch.org/t/random-seed-initialization/7854/28\n",
        "#https://pytorch.org/docs/stable/notes/randomness.html"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f91d9e37730>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8PyrmfFNKFE"
      },
      "source": [
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nw2vtabYQ_rA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fcb56e8-5d50-488c-f1a1-94e6a9625fbe"
      },
      "source": [
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # an affine operation: y = Wx + b\n",
        "        self.fc1 = nn.Linear(28*28, 500, False)  # 28*28 from image dimension \n",
        "        self.fc2 = nn.Linear(500, 300,False)\n",
        "        self.fc3 = nn.Linear(300, 5,False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "net = Net()\n",
        "if torch.cuda.is_available():\n",
        "  net = net.cuda()\n",
        "\n",
        "print(net)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=784, out_features=500, bias=False)\n",
            "  (fc2): Linear(in_features=500, out_features=300, bias=False)\n",
            "  (fc3): Linear(in_features=300, out_features=5, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_oj8JgSZs83"
      },
      "source": [
        "def data_loader(batch_size=1024, n_workers=2):\n",
        "\n",
        "    train_data_th = datasets.MNIST(root='./datasets', download=True, train=True)\n",
        "    #test_data_th = datasets.MNIST(root='./datasets', download=True, train=False)\n",
        "\n",
        "    label = [1, 2, 3 ,4, 6]\n",
        "    data_fea = np.array(train_data_th.data[:]).reshape([-1, 28 * 28]).astype(np.float32)\n",
        "    data_fea = (data_fea / 255)\n",
        "    data_gnd = np.array(train_data_th.targets)\n",
        "    ctr1_idx = np.where(data_gnd[:] == label[0])\n",
        "    ctr2_idx = np.where(data_gnd[:] == label[1])\n",
        "    ctr3_idx = np.where(data_gnd[:] == label[2])\n",
        "    ctr4_idx = np.where(data_gnd[:] == label[3])\n",
        "    ctr6_idx = np.where(data_gnd[:] == label[4])\n",
        "    ctr1_idx = np.array(ctr1_idx)\n",
        "    ctr1_idx = ctr1_idx[0,0:1500]\n",
        "    ctr2_idx = np.array(ctr2_idx)\n",
        "    ctr2_idx = ctr2_idx[0,0:1500]\n",
        "    ctr3_idx = np.array(ctr3_idx)\n",
        "    ctr3_idx = ctr3_idx[0,0:1500]\n",
        "    ctr4_idx = np.array(ctr4_idx)\n",
        "    ctr4_idx = ctr4_idx[0,0:1500]\n",
        "    ctr6_idx = np.array(ctr6_idx)\n",
        "    ctr6_idx = ctr6_idx[0,0:1500]\n",
        "    train_idx = np.concatenate((ctr1_idx[:500], ctr2_idx[:500], ctr3_idx[:500], ctr4_idx[:500], ctr6_idx[:500]),axis = None)\n",
        "    validation_idx = np.concatenate((ctr1_idx[500:1000], ctr2_idx[500:1000], ctr3_idx[500:1000], ctr4_idx[500:1000], ctr6_idx[500:1000]),axis = None)\n",
        "    test_idx = np.concatenate((ctr1_idx[1000:1500], ctr2_idx[1000:1500], ctr3_idx[1000:1500], ctr4_idx[1000:1500], ctr6_idx[1000:1500]),axis = None)\n",
        "\n",
        "    data_train = data_fea[train_idx]\n",
        "    target_train = data_gnd[train_idx]\n",
        "\n",
        "    data_validation = data_fea[validation_idx]\n",
        "    target_validation = data_gnd[validation_idx]\n",
        "\n",
        "    data_test = data_fea[test_idx]\n",
        "    target_test = data_gnd[test_idx]\n",
        "\n",
        "    ##not sure what this is doing but it was here in the og\n",
        "    dtrain_mean = data_train.mean(axis=0)\n",
        "    data_train -= dtrain_mean\n",
        "    data_validation -=dtrain_mean\n",
        "    data_test -= dtrain_mean\n",
        "    ##\n",
        "\n",
        "    #######\n",
        "    #https://discuss.pytorch.org/t/indexerror-target-2-is-out-of-bounds/69614/24 I AM SO HAPPY I FOUND THIS FORUM!\n",
        "    tensor_target_train = torch.from_numpy(target_train)\n",
        "    # print(tensor_target_train.size())\n",
        "    # print(min(tensor_target_train))\n",
        "    # print(max(tensor_target_train))\n",
        "    unique_targets_train = torch.unique(tensor_target_train)\n",
        "    # print('unique_targets_train: {}'.format(unique_targets_train))\n",
        "\n",
        "    new_tensor_target_train = torch.empty_like(tensor_target_train)\n",
        "    for idx, t in enumerate(unique_targets_train):\n",
        "        # print('replacing {} with {}'.format(t, idx))\n",
        "        new_tensor_target_train[tensor_target_train == t] = idx\n",
        "    # print(new_tensor_target_train.size())\n",
        "    # print(min(new_tensor_target_train))\n",
        "    # print(max(new_tensor_target_train))\n",
        "\n",
        "    tensor_target_validation = torch.from_numpy(target_validation)\n",
        "    unique_targets_validation = torch.unique(tensor_target_validation)\n",
        "    new_tensor_target_validation = torch.empty_like(tensor_target_validation)\n",
        "    for idx, t in enumerate(unique_targets_validation):\n",
        "      new_tensor_target_validation[tensor_target_validation == t] = idx\n",
        "\n",
        "    tensor_target_test = torch.from_numpy(target_test)\n",
        "    unique_targets_test = torch.unique(tensor_target_test)\n",
        "    new_tensor_target_test = torch.empty_like(tensor_target_test)\n",
        "    for idx, t in enumerate(unique_targets_test):\n",
        "      new_tensor_target_test[tensor_target_test == t] = idx\n",
        "\n",
        "\n",
        "    train_data = TensorDataset(torch.from_numpy(data_train), new_tensor_target_train)\n",
        "    validation_data = TensorDataset(torch.from_numpy(data_validation), new_tensor_target_validation)\n",
        "    test_data = TensorDataset(torch.from_numpy(data_test), new_tensor_target_test)\n",
        "\n",
        "    train_loader = DataLoader(train_data, num_workers=n_workers, batch_size=batch_size, shuffle=True,worker_init_fn=seed_worker,generator=g)\n",
        "    validation_loader = DataLoader(validation_data, num_workers = n_workers, batch_size = batch_size, shuffle = True,worker_init_fn=seed_worker,generator=g)\n",
        "    test_loader = DataLoader(test_data, num_workers=n_workers, batch_size=batch_size, shuffle=False,worker_init_fn=seed_worker,generator=g)\n",
        "\n",
        "    return train_loader, validation_loader, test_loader"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6mJjdV6aLt4"
      },
      "source": [
        "def calc_acc(loader, net):\n",
        "    correct_cnt = 0\n",
        "    total_cnt = 0\n",
        "    net.eval()\n",
        "    for batch_inputs, batch_labels in loader:\n",
        "        if torch.cuda.is_available():\n",
        "            batch_inputs = batch_inputs.cuda()\n",
        "            batch_labels = batch_labels.cuda()\n",
        "        total_cnt += len(batch_inputs)\n",
        "        out = net(batch_inputs[:])\n",
        "        _, pred_labels = torch.max(out.data, 1)\n",
        "        correct_cnt += (pred_labels == batch_labels).sum().item()\n",
        "\n",
        "    return correct_cnt / total_cnt\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yywffSSQoLBl"
      },
      "source": [
        "plotlr = []\n",
        "plotval = []\n",
        "plottrain = []\n",
        "plotdiftrainval = []\n",
        "\n",
        "plotepoch = []\n",
        "plotloss = []"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yY9v3-6qb1Pd"
      },
      "source": [
        "nnloss = torch.nn.CrossEntropyLoss()\n",
        "from torch import nn, optim\n",
        "\n",
        "#I optimized lr, momentum, weight_decay, batch, epoch, step_size, and gamma\n",
        "#values are seen in the code blocks below\n",
        "\n",
        "def train_net(net):\n",
        "    # Your task is to choose best parameters of optimization (momentum, batch size, learning rate, l2 regularization).\n",
        "    train_loader, validation_loader, test_loader = data_loader(1024, 2)\n",
        "    params = list(filter(lambda p: p.requires_grad, net.parameters()))\n",
        "    #print(f\"I value is {i}\")\n",
        "    optimizer = optim.SGD(params, lr=0.1,momentum=1,weight_decay=0)  # lr = learning rate, momentum = momentum, weight delay = l2 regulaization\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=80,gamma=1)\n",
        "    epochs = 30\n",
        "    for epoch in range(epochs):\n",
        "        avg_loss = []\n",
        "        net.train()\n",
        "        for x, target in train_loader:\n",
        "            if torch.cuda.is_available():\n",
        "                x = x.cuda()[:]\n",
        "                target = target.cuda().to(dtype=torch.long)\n",
        "            optimizer.zero_grad()\n",
        "            out = net(x)\n",
        "            loss = nnloss(out, target)\n",
        "            avg_loss.append(loss.item())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        #print(f\"\\tepoch #{epoch} is finished.\")\n",
        "        #plotepoch.append(epoch)\n",
        "        #print(f\"\\t  avg. train loss: {np.mean(avg_loss):.6f}\")\n",
        "        #plotloss.append(np.mean(avg_loss))\n",
        "    # train_acc = calc_acc(train_loader, net)\n",
        "    # print(f'Train Accurary: {train_acc}')\n",
        "    # plottrain.append(train_acc)\n",
        "    # validation_acc = calc_acc(validation_loader, net)\n",
        "    # print(f'Validation Accurary: {validation_acc}')\n",
        "    # plotval.append(validation_acc)\n",
        "    # #plotlr.append(i)\n",
        "    # dif = train_acc - validation_acc\n",
        "    # plotdiftrainval.append(dif)\n",
        "    # print(f\"Difference between Train and Val {dif}\")\n",
        "    # #plt.semilogx(plotlr, plotval, color=\"blue\", label=\"Val_Score\", marker=\"o\")\n",
        "    # #plt.semilogx(plotlr, plottrain, color=\"red\", label=\"Train_Score\", marker=\"o\")\n",
        "    # plt.semilogx(plotval, color=\"blue\", label=\"Val_Score\", marker=\"o\")\n",
        "    # plt.semilogx(plottrain, color=\"red\", label=\"Train_Score\", marker=\"o\")\n",
        "    # plt.title(f'lrate = {i} ')\n",
        "    # plt.show()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFuQlxQkv3pX"
      },
      "source": [
        "The block of code down below is my attempts of trying to running the best learning rate. Currently, I am running into the issue of not understanding how to reset the parameters or even if i do need to reset the parameters\n",
        "look at this [website](https://discuss.pytorch.org/t/reset-the-parameters-of-a-model/29839). they explain some things how to reset the parameters\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ez4PNdY_CnD"
      },
      "source": [
        "plotval.clear()\n",
        "plottrain.clear()\n",
        "plotdiftrainval.clear()\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6h9aA-GnstZ"
      },
      "source": [
        "# lrate = [10**(-7), 10**(-6), 10**(-5), 10**(-4), 10**(-3), 10**(-2), 0.1, 1]\n",
        "# lrate2 = np.linspace(0,.3,31)\n",
        "# lrate3 = np.linspace(0,0.3,31)\n",
        "# for i in range(len(lrate3)) :\n",
        "#     net = Net()\n",
        "#     if torch.cuda.is_available():\n",
        "#         net = net.cuda()\n",
        "#     train_net(net,lrate3[i])\n",
        "\n",
        "#first parameter optimized, just found where highest val accurary is, it was at 0.1\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmGReHKIV2dW"
      },
      "source": [
        "# momentumrate = np.linspace(0,1,11)\n",
        "# for i in range(len(momentumrate)) :\n",
        "#     net = Net()\n",
        "#     if torch.cuda.is_available():\n",
        "#         net = net.cuda()\n",
        "#     train_net(net,momentumrate[i])\n",
        "\n",
        "#second parameter optimized, found highest val at 1"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5wQlYibYlFa"
      },
      "source": [
        "# weight_decayrate = np.linspace(0,1,11)\n",
        "# for i in range(len(weight_decayrate)) :\n",
        "#     net = Net()\n",
        "#     if torch.cuda.is_available():\n",
        "#         net = net.cuda()\n",
        "#     train_net(net,weight_decayrate[i])\n",
        "#third parameter optimized, found highest val accurary at 0"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ifv2WeaUkZ9"
      },
      "source": [
        "# batchnum = [128,256,512,1024,2048]\n",
        "# for i in range(len(batchnum)) :\n",
        "#     net = Net()\n",
        "#     if torch.cuda.is_available():\n",
        "#         net = net.cuda()\n",
        "#     train_net(net,batchnum[i])\n",
        "#fourth parameter optimized, found highest val accurary at 1024"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgGuT0tNmMsW"
      },
      "source": [
        "# epochrate = [0,1,10,20,30,40,50,60,70,80,90,100]\n",
        "# for i in range(len(epochrate)) :\n",
        "#     net = Net()\n",
        "#     if torch.cuda.is_available():\n",
        "#         net = net.cuda()\n",
        "#     train_net(net,epochrate[i])\n",
        "#fifth parameter optimized, found highest val accuary at 30"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYrcCWxOnwRe"
      },
      "source": [
        "# stepsizerate = np.linspace(0,100,101)\n",
        "# for i in range(len(stepsizerate)) :\n",
        "#     net = Net()\n",
        "#     if torch.cuda.is_available():\n",
        "#         net = net.cuda()\n",
        "#     train_net(net,stepsizerate[i])\n",
        "#sixth parameter optimized, found highest val accurary at 80"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPG5M7hkg67P"
      },
      "source": [
        "# gammarate = np.linspace(0,1,11)\n",
        "# for i in range(len(gammarate)) :\n",
        "#     net = Net()\n",
        "#     if torch.cuda.is_available():\n",
        "#         net = net.cuda()\n",
        "#     train_net(net,gammarate[i])\n",
        "#seventh parameter optimized, found highest val accurary at 1"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgIOhDErcR2H"
      },
      "source": [
        "train_net(net)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nea1fzQ57g0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "441c01ae-934f-4480-fe16-ba88040217d0"
      },
      "source": [
        "train_loader, validation_loader, test_loader = data_loader()\n",
        "print(f'train accurary: {calc_acc(train_loader,net)}')\n",
        "print(f'validation accurary: {calc_acc(validation_loader,net)}')\n",
        "print(f'test accurary: {calc_acc(test_loader,net)}')\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train accurary: 0.9932\n",
            "validation accurary: 0.9572\n",
            "test accurary: 0.952\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofm5BhTjCEFc"
      },
      "source": [
        "#https://www.geeksforgeeks.org/python-remove-negative-elements-in-list/\n",
        "# tmpplot = [ele for ele in plotdiftrainval if ele > 0]\n",
        "# minDif = max(plotval)\n",
        "# mindDifidx = plotval.index(minDif)\n",
        "# print(minDif)\n",
        "# print(mindDifidx)"
      ],
      "execution_count": 18,
      "outputs": []
    }
  ]
}