{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nw2vtabYQ_rA",
    "outputId": "1720d68d-a962-4471-a876-7703e1a34ebe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=500, bias=False)\n",
      "  (fc2): Linear(in_features=500, out_features=300, bias=False)\n",
      "  (fc3): Linear(in_features=300, out_features=5, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(0)\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(784, 500, False)  # 28*28 from image dimension \n",
    "        self.fc2 = nn.Linear(500, 300,False)\n",
    "        self.fc3 = nn.Linear(300, 5,False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "#net = Net().cuda()\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "B_oj8JgSZs83"
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "def data_loader(batch_size=2048, n_workers=2):\n",
    "    train_data_th = datasets.MNIST(root='./datasets', download=True, train=True)\n",
    "    test_data_th = datasets.MNIST(root='./datasets', download=True, train=False)\n",
    "\n",
    "    label = [1, 2, 3 ,4, 6]\n",
    "    data_train_fea = np.array(train_data_th.data[:]).reshape([-1, 28 * 28]).astype(np.float32)\n",
    "    data_train_fea = (data_train_fea / 255)\n",
    "    data_train_gnd = np.array(train_data_th.targets)\n",
    "    ctr1_idx = np.where(data_train_gnd[:] == label[0])\n",
    "    ctr2_idx = np.where(data_train_gnd[:] == label[1])\n",
    "    ctr3_idx = np.where(data_train_gnd[:] == label[2])\n",
    "    ctr4_idx = np.where(data_train_gnd[:] == label[3])\n",
    "    ctr6_idx = np.where(data_train_gnd[:] == label[4])\n",
    "    ctr1_idx = np.array(ctr1_idx)\n",
    "    ctr2_idx = np.array(ctr2_idx)\n",
    "    ctr3_idx = np.array(ctr3_idx)\n",
    "    ctr4_idx = np.array(ctr4_idx)\n",
    "    ctr6_idx = np.array(ctr6_idx)\n",
    "    train_idx = np.concatenate((ctr1_idx, ctr2_idx, ctr3_idx, ctr4_idx, ctr6_idx),axis = None)\n",
    "    data_train = data_train_fea[train_idx]\n",
    "    target_train = data_train_gnd[train_idx]\n",
    "\n",
    "    dtrain_mean = data_train.mean(axis=0)\n",
    "    data_train -= dtrain_mean\n",
    "\n",
    "    data_test_fea = np.array(test_data_th.data[:]).reshape([-1, 28 * 28]).astype(np.float32)\n",
    "    data_test_fea = (data_test_fea / 255).astype(np.float32)\n",
    "    data_test_gnd = np.array(test_data_th.targets)\n",
    "    cte1_idx = np.where(data_test_gnd[:] == label[0])\n",
    "    cte2_idx = np.where(data_test_gnd[:] == label[1])\n",
    "    cte3_idx = np.where(data_test_gnd[:] == label[2])\n",
    "    cte4_idx = np.where(data_test_gnd[:] == label[3])\n",
    "    cte6_idx = np.where(data_test_gnd[:] == label[4])\n",
    "    cte1_idx = np.array(cte1_idx)\n",
    "    cte2_idx = np.array(cte2_idx)\n",
    "    cte3_idx = np.array(cte3_idx)\n",
    "    cte4_idx = np.array(cte4_idx)\n",
    "    cte6_idx = np.array(cte6_idx)\n",
    "    test_idx = np.concatenate((cte1_idx, cte2_idx, cte3_idx, cte4_idx, cte6_idx),axis = None)\n",
    "    data_test = data_test_fea[test_idx]\n",
    "    target_test = data_test_gnd[test_idx]\n",
    "\n",
    "    data_test -= dtrain_mean  \n",
    "\n",
    "    #https://discuss.pytorch.org/t/indexerror-target-2-is-out-of-bounds/69614/24 I AM SO HAPPY I FOUND THIS FORUM!\n",
    "    tensor_target_train = torch.from_numpy(target_train)\n",
    "    # print(tensor_target_train.size())\n",
    "    # print(min(tensor_target_train))\n",
    "    # print(max(tensor_target_train))\n",
    "    unique_targets_train = torch.unique(tensor_target_train)\n",
    "    # print('unique_targets_train: {}'.format(unique_targets_train))\n",
    "\n",
    "    new_tensor_target_train = torch.empty_like(tensor_target_train)\n",
    "    for idx, t in enumerate(unique_targets_train):\n",
    "        # print('replacing {} with {}'.format(t, idx))\n",
    "        new_tensor_target_train[tensor_target_train == t] = idx\n",
    "    # print(new_tensor_target_train.size())\n",
    "    # print(min(new_tensor_target_train))\n",
    "    # print(max(new_tensor_target_train))\n",
    "\n",
    "    ###################################################\n",
    "\n",
    "    tensor_target_test = torch.from_numpy(target_test)\n",
    "    # print(tensor_target_test.size())\n",
    "    # print(min(tensor_target_test))\n",
    "    # print(max(tensor_target_test))\n",
    "    unique_targets_test = torch.unique(tensor_target_test)\n",
    "    # print('unique_targets_test: {}'.format(unique_targets_test))\n",
    "\n",
    "    new_tensor_target_test = torch.empty_like(tensor_target_test)\n",
    "    for idx, t in enumerate(unique_targets_test):\n",
    "        # print('replacing {} with {}'.format(t, idx))\n",
    "        new_tensor_target_test[tensor_target_test == t] = idx\n",
    "    # print(new_tensor_target_test.size())\n",
    "    # print(min(new_tensor_target_test))\n",
    "    # print(max(new_tensor_target_test))\n",
    "\n",
    "    train_data = TensorDataset(torch.from_numpy(data_train), new_tensor_target_train)\n",
    "    test_data = TensorDataset(torch.from_numpy(data_test), new_tensor_target_test)\n",
    "\n",
    "    train_loader = DataLoader(train_data, num_workers=n_workers, batch_size=batch_size, shuffle=True,)\n",
    "    test_loader = DataLoader(test_data, num_workers=n_workers, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "s6mJjdV6aLt4"
   },
   "outputs": [],
   "source": [
    "def calc_acc(loader, net):\n",
    "    correct_cnt = 0\n",
    "    total_cnt = 0\n",
    "    for batch_inputs, batch_labels in loader:\n",
    "        #batch_inputs = batch_inputs.cuda()\n",
    "        #batch_labels = batch_labels.cuda()\n",
    "        batch_inputs = batch_inputs\n",
    "        batch_labels = batch_labels\n",
    "        total_cnt += len(batch_inputs)\n",
    "        out = net(batch_inputs[:])\n",
    "        _, pred_labels = torch.max(out.data, 1)\n",
    "        correct_cnt += (pred_labels == batch_labels).sum().item()\n",
    "\n",
    "    return correct_cnt / total_cnt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SerNz3tsaWI-",
    "outputId": "983c0f25-f4f7-4bc5-cf79-bc5b9a45eb5a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13777604064881765"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader, test_loader = data_loader()\n",
    "calc_acc(test_loader, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "yY9v3-6qb1Pd"
   },
   "outputs": [],
   "source": [
    "nnloss = torch.nn.CrossEntropyLoss()\n",
    "from torch import nn, optim\n",
    "\n",
    "def train_net(net):\n",
    "    #Your task is to choose best parameters of optimization (momentum, batch size, learning rate, l2 regularization).\n",
    "    train_loader, test_loader = data_loader(2048,2)\n",
    "    params = list(filter(lambda p: p.requires_grad, net.parameters()))\n",
    "    optimizer = optim.SGD(params, lr=0.1, momentum=0.9, nesterov=True)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
    "    epochs = 10\n",
    "    for epoch in range(epochs):\n",
    "        avg_loss = []\n",
    "        for x, target in train_loader:\n",
    "            #print(min(target))\n",
    "            #print(max(target))\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            #x = x.cuda()[:]\n",
    "            x = x[:]\n",
    "            #target = target.cuda().to(dtype=torch.long)\n",
    "            target = target.to(dtype=torch.long)\n",
    "            out = net(x)\n",
    "            loss = nnloss(out, target)\n",
    "            #avg_loss.append(loss.item().cuda())\n",
    "            avg_loss.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        print(f\"\\tepoch #{epoch} is finished.\")\n",
    "        print(f\"\\t  avg. train loss: {np.mean(avg_loss):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TLYO47_EcdXN",
    "outputId": "1d4fd35f-025f-41ea-c2a4-2b5d7e12dff0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tepoch #0 is finished.\n",
      "\t  avg. train loss: 1.326736\n",
      "\tepoch #1 is finished.\n",
      "\t  avg. train loss: 0.278293\n",
      "\tepoch #2 is finished.\n",
      "\t  avg. train loss: 0.146641\n",
      "\tepoch #3 is finished.\n",
      "\t  avg. train loss: 0.107073\n",
      "\tepoch #4 is finished.\n",
      "\t  avg. train loss: 0.088869\n",
      "\tepoch #5 is finished.\n",
      "\t  avg. train loss: 0.078785\n",
      "\tepoch #6 is finished.\n",
      "\t  avg. train loss: 0.071574\n",
      "\tepoch #7 is finished.\n",
      "\t  avg. train loss: 0.066190\n",
      "\tepoch #8 is finished.\n",
      "\t  avg. train loss: 0.062012\n",
      "\tepoch #9 is finished.\n",
      "\t  avg. train loss: 0.058668\n"
     ]
    }
   ],
   "source": [
    "train_net(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ojWp_ptecw_6",
    "outputId": "070da997-1410-49d5-e55c-0dab84836a45"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9837795583349619"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_acc(test_loader, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "GroupF_Project2_Part1_Neural_Network.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
